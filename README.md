# ğŸ” Multimodal RAG Chatbot# ğŸ” Multimodal RAG Chatbot# Multimodal RAG Chatbot



A production-ready **Retrieval-Augmented Generation (RAG)** chatbot that processes multimodal documents (PDFs with text, images, and tables) and answers questions using Google's Gemini LLM.



---A production-ready **Retrieval-Augmented Generation (RAG)** chatbot that processes multimodal documents (PDFs with text, images, and tables) and answers questions using Google's Gemini LLM.A Streamlit-based multimodal RAG (Retrieval-Augmented Generation) chatbot that can process PDFs, images, and text files.



## ğŸ“‹ Table of Contents



- [Features](#-features)---## Features

- [Architecture](#-architecture)

- [Technology Stack](#-technology-stack)

- [Installation](#-installation)

- [Configuration](#-configuration)## ğŸ“‹ Table of Contents- **Document Processing**: Load PDFs, images, and text files with OCR support

- [Usage](#-usage)

- [Project Structure](#-project-structure)- **Hybrid Search**: Combines FAISS vector search with BM25 keyword search

- [How It Works](#-how-it-works)

- [API Reference](#-api-reference)- [Features](#-features)- **Reranking**: Cross-encoder reranking for improved relevance

- [Troubleshooting](#-troubleshooting)

- [Architecture](#-architecture)- **Streaming Responses**: Real-time LLM response streaming

---

- [Technology Stack](#-technology-stack)- **Citation Tracking**: Source attribution for all responses

## âœ¨ Features

- [Installation](#-installation)

### Core Capabilities

- [Configuration](#-configuration)## Setup

| Feature | Description |

|---------|-------------|- [Usage](#-usage)

| ğŸ“„ **Multimodal Document Processing** | Extract text, images, and tables from PDFs |

| ğŸ–¼ï¸ **True Multimodal Embeddings** | CLIP model embeds both text AND images in unified vector space |- [Project Structure](#-project-structure)1. Install dependencies:

| ğŸ” **Hybrid Retrieval** | Combines semantic search (FAISS) with keyword search (BM25) |

| ğŸ¯ **Cross-Encoder Reranking** | Re-scores results for higher precision |- [How It Works](#-how-it-works)```bash

| ğŸ’¬ **Conversational Memory** | Remembers context across multiple turns |

| ğŸ”„ **Query Reformulation** | Automatically makes follow-up questions standalone |- [API Reference](#-api-reference)pip install -r requirements.txt

| ğŸ“Š **Table Extraction** | Converts PDF tables to searchable markdown |

| ğŸ‘ï¸ **OCR Support** | Extracts text from images using EasyOCR |- [Troubleshooting](#-troubleshooting)```



### User Interface



| Feature | Description |---2. Configure environment variables in `.env`:

|---------|-------------|

| ğŸ’» **Streamlit Chat Interface** | Modern, responsive design |```

| ğŸ“ **File Upload** | Drag-and-drop PDF, image, and text files |

| ğŸ“š **Source Citations** | See exactly where answers come from |## âœ¨ FeaturesGOOGLE_API_KEY=your-google-api-key

| âš¡ **Streaming Responses** | Real-time token-by-token output |

```

---

### Core Capabilities

## ğŸ—ï¸ Architecture

3. Run the app:

### High-Level System Overview

| Feature | Description |```bash

```

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”|---------|-------------|streamlit run app.py

â”‚                    Streamlit Web Interface                  â”‚

â”‚  (Chat, File Upload, Source Display, Settings)              â”‚| ğŸ“„ **Multimodal Document Processing** | Extract text, images, and tables from PDFs |```

â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

                             â”‚| ğŸ–¼ï¸ **True Multimodal Embeddings** | CLIP model embeds both text AND images in unified vector space |

        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”

        â”‚                    â”‚                    â”‚| ğŸ” **Hybrid Retrieval** | Combines semantic search (FAISS) with keyword search (BM25) |## Project Structure

        â–¼                    â–¼                    â–¼

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”| ğŸ¯ **Cross-Encoder Reranking** | Re-scores results for higher precision |

â”‚   Document   â”‚    â”‚   RAG Pipeline â”‚   â”‚ Conversation â”‚

â”‚  Processor   â”‚    â”‚  & Retrieval   â”‚   â”‚    Memory    â”‚| ğŸ’¬ **Conversational Memory** | Remembers context across multiple turns |```

â”‚ (PDF, IMG)   â”‚    â”‚   (FAISS+BM25) â”‚   â”‚ (Context)    â”‚

â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜| ğŸ”„ **Query Reformulation** | Automatically makes follow-up questions standalone |multimodal_rag_chatbot/

        â”‚                    â”‚                    â”‚

        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜| ğŸ“Š **Table Extraction** | Converts PDF tables to searchable markdown |â”œâ”€â”€ app.py                    # Main Streamlit app

                             â”‚

                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”| ğŸ‘ï¸ **OCR Support** | Extracts text from images using EasyOCR |â”œâ”€â”€ config.py                 # Settings & API keys

                    â”‚  LLM Service    â”‚

                    â”‚  (Gemini API)   â”‚â”œâ”€â”€ core/                     # Core processing modules

                    â”‚  (Streaming)    â”‚

                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜### User Interfaceâ”‚   â”œâ”€â”€ document_processor.py # Document loading & chunking

```

â”‚   â”œâ”€â”€ embedding_engine.py   # CLIP embeddings + FAISS

### Data Flow

| Feature | Description |â”‚   â””â”€â”€ retrieval_engine.py   # Hybrid search & reranking

```

1. Document Upload|---------|-------------|â”œâ”€â”€ services/                 # Business logic

   â†“

2. Text Extraction (PyMuPDF) + OCR (EasyOCR) + Table Extraction| ğŸ’» **Streamlit Chat Interface** | Modern, responsive design |â”‚   â”œâ”€â”€ llm_service.py        # LLM generation

   â†“

3. Chunking (RecursiveCharacterTextSplitter: 1000 chars, 200 overlap)| ğŸ“ **File Upload** | Drag-and-drop PDF, image, and text files |â”‚   â””â”€â”€ rag_pipeline.py       # End-to-end orchestration

   â†“

4. Embedding (CLIP: sentence-transformers/clip-ViT-B-32)| ğŸ“š **Source Citations** | See exactly where answers come from |â”œâ”€â”€ components/               # Streamlit UI components

   â”œâ”€ Text embeddings (512-dim)

   â””â”€ Image embeddings (512-dim, same space)| âš¡ **Streaming Responses** | Real-time token-by-token output |â”‚   â”œâ”€â”€ sidebar.py            # File upload sidebar

   â†“

5. Indexingâ”‚   â”œâ”€â”€ chat_interface.py     # Chat UI

   â”œâ”€ FAISS (semantic search via cosine similarity)

   â””â”€ BM25 (keyword search)---â”‚   â””â”€â”€ document_viewer.py    # Source display

   â†“

6. Query Processingâ”œâ”€â”€ data/                     # Data storage

   â”œâ”€ Reformulate if follow-up (ConversationMemory)

   â”œâ”€ Embed query with CLIP## ğŸ—ï¸ Architectureâ”‚   â”œâ”€â”€ uploads/              # Uploaded documents

   â””â”€ Hybrid retrieval (RRF fusion)

   â†“â”‚   â”œâ”€â”€ faiss_index/          # Vector store

7. Reranking (Cross-encoder: ms-marco-MiniLM-L-12-v2)

   â†“### High-Level System Overviewâ”‚   â””â”€â”€ bm25_index/           # BM25 index

8. Generation (Gemini with streaming)

   â†“â””â”€â”€ utils/                    # Utility functions

9. Display with source citations

``````    â””â”€â”€ helpers.py



---â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”```



## ğŸ’» Technology Stackâ”‚                         USER INTERFACE                               â”‚

â”‚                      (Streamlit Chat App)                            â”‚

| Component | Technology |â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

|-----------|-----------|                                    â”‚

| **LLM** | Google Gemini API |                                    â–¼

| **Embeddings** | CLIP (sentence-transformers) |â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”

| **Vector DB** | FAISS (IndexFlatIP) |â”‚                         RAG PIPELINE                                 â”‚

| **Keyword Search** | BM25 (rank-bm25) |â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚

| **Reranking** | Cross-Encoder (sentence-transformers) |â”‚  â”‚   Query     â”‚  â”‚   Hybrid    â”‚  â”‚  Reranker   â”‚  â”‚    LLM      â”‚ â”‚

| **PDF Processing** | PyMuPDF (fitz) |â”‚  â”‚Reformulationâ”‚â†’ â”‚  Retrieval  â”‚â†’ â”‚ (Cross-Enc) â”‚â†’ â”‚  (Gemini)   â”‚ â”‚

| **OCR** | EasyOCR |â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚

| **UI Framework** | Streamlit |â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

| **LLM Integration** | LangChain (langchain-google-genai) |                                    â”‚

| **Text Splitting** | LangChain TextSplitters |                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”

| **Python Version** | 3.8+ |                    â–¼                               â–¼

        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”           â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”

---        â”‚   FAISS Index     â”‚           â”‚   BM25 Index      â”‚

        â”‚ (Vector Search)   â”‚           â”‚ (Keyword Search)  â”‚

## ğŸ“¦ Installation        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜           â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

                    â”‚                               â”‚

### Prerequisites                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

- Python 3.8 or higher                                    â–¼

- Google API key (free at [ai.google.dev](https://ai.google.dev))â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”

â”‚                    DOCUMENT PROCESSING                               â”‚

### Stepsâ”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚

â”‚  â”‚    Text     â”‚  â”‚   Images    â”‚  â”‚   Tables    â”‚  â”‚    OCR      â”‚ â”‚

1. **Clone the repository**â”‚  â”‚  Extraction â”‚  â”‚  (+ CLIP)   â”‚  â”‚ (Markdown)  â”‚  â”‚  (EasyOCR)  â”‚ â”‚

```bashâ”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚

git clone https://github.com/Goutam-aswani/Multimodal-RAG-chatbot.gitâ””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

cd Multimodal-RAG-chatbot```

```

### Multimodal Embedding Architecture

2. **Create virtual environment**

```bash```

python -m venv venv                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”

source venv/bin/activate  # On Windows: venv\Scripts\activate                    â”‚         CLIP Model (ViT-B-32)       â”‚

```                    â”‚   Shared Text-Image Embedding Space  â”‚

                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

3. **Install dependencies**                                      â”‚

```bash                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”

pip install -r requirements.txt                    â”‚                 â”‚                 â”‚

```                    â–¼                 â–¼                 â–¼

            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”

4. **Create `.env` file**            â”‚    Text     â”‚   â”‚   Images    â”‚   â”‚   Tables    â”‚

```bash            â”‚  Encoder    â”‚   â”‚  Encoder    â”‚   â”‚ (as Text)   â”‚

echo "GOOGLE_API_KEY=your_api_key_here" > .env            â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

```                    â”‚                 â”‚                 â”‚

                    â–¼                 â–¼                 â–¼

5. **Run the app**            [512-dim vector]  [512-dim vector]  [512-dim vector]

```bash                    â”‚                 â”‚                 â”‚

streamlit run app.py                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

```                                      â–¼

                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”

The app will open at `http://localhost:8501`                    â”‚        Unified FAISS Index          â”‚

                    â”‚  (Text + Images in same space)      â”‚

---                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

```

## âš™ï¸ Configuration

---

### Environment Variables (`.env`)

## ğŸ› ï¸ Technology Stack

```env

# Required| Component | Technology | Purpose |

GOOGLE_API_KEY=your-gemini-api-key|-----------|------------|---------|

| **Document Processing** | PyMuPDF (fitz) | PDF text, image, table extraction |

# Optional| **OCR** | EasyOCR | Extract text from images |

CHUNK_SIZE=1000              # Text chunk size| **Embeddings** | CLIP (ViT-B-32) | Multimodal text & image embeddings |

CHUNK_OVERLAP=200            # Chunk overlap| **Vector Store** | FAISS | Fast similarity search |

MAX_MEMORY_TURNS=5           # Conversation history turns| **Keyword Search** | BM25 (rank-bm25) | Lexical matching |

TOP_K_RETRIEVAL=10           # Top K results to retrieve| **Reranking** | Cross-Encoder | Precision improvement |

RERANK_TOP_K=5               # Top K results after reranking| **LLM** | Google Gemini | Response generation |

```| **UI Framework** | Streamlit | Web interface |

| **Configuration** | Pydantic Settings | Type-safe config |

### Supported File Types

---

| Type | Extensions | Processing |

|------|-----------|-----------|## ğŸ“¦ Installation

| **PDF** | `.pdf` | Text, images, tables |

| **Images** | `.jpg`, `.png`, `.jpeg` | OCR + CLIP embedding |### Prerequisites

| **Text** | `.txt`, `.md` | Direct text processing |

- Python 3.9 or higher

---- Google API Key (for Gemini LLM)

- 4GB+ RAM recommended

## ğŸš€ Usage

### Step 1: Clone the Repository

### Quick Start

```bash

1. **Upload documents** - Click "Upload Documents" in the sidebargit clone <repository-url>

2. **Process** - Click "Process Documents" buttoncd multimodal_rag_chatbot

3. **Ask questions** - Type in the chat input```

4. **View sources** - Expand "View Sources" for context

### Step 2: Create Virtual Environment

### Example Queries

```bash

- "What is the main topic of this document?"# Create virtual environment

- "Summarize the key points"python -m venv venv

- "What does the image show?"

- "Can you explain the table?"# Activate (Windows)

- "Follow-up: Tell me more about..." (uses conversation memory)venv\Scripts\activate



---# Activate (Linux/Mac)

source venv/bin/activate

## ğŸ“ Project Structure```



```### Step 3: Install Dependencies

multimodal_rag_chatbot/

â”œâ”€â”€ app.py                      # Main Streamlit app```bash

â”œâ”€â”€ config.py                   # Settings & configurationpip install -r requirements.txt

â”œâ”€â”€ requirements.txt            # Python dependencies```

â”œâ”€â”€ .env                        # Environment variables

â”œâ”€â”€ .gitignore                  # Git ignore file### Step 4: Configure Environment

â”œâ”€â”€ README.md                   # This file

â”œâ”€â”€ QUICKSTART.md               # Quick start guideCreate a `.env` file in the project root:

â”‚

â”œâ”€â”€ core/                       # Core processing modules```env

â”‚   â”œâ”€â”€ document_processor.py   # Document loading & chunking# Required

â”‚   â”œâ”€â”€ embedding_engine.py     # CLIP embeddings + FAISSGOOGLE_API_KEY=your_google_api_key_here

â”‚   â””â”€â”€ retrieval_engine.py     # Hybrid search & reranking

â”‚# Optional (has defaults)

â”œâ”€â”€ services/                   # Business logicDEFAULT_MODEL=gemini-2.0-flash

â”‚   â”œâ”€â”€ llm_service.py         # LLM generation & memory```

â”‚   â””â”€â”€ rag_pipeline.py        # End-to-end orchestration

â”‚### Step 5: Run the Application

â”œâ”€â”€ components/                 # Streamlit UI components

â”‚   â”œâ”€â”€ sidebar.py             # File upload sidebar```bash

â”‚   â”œâ”€â”€ chat_interface.py       # Chat UIstreamlit run app.py

â”‚   â””â”€â”€ document_viewer.py      # Source display```

â”‚

â””â”€â”€ data/                       # Data storageThe app will open at `http://localhost:8501`

    â”œâ”€â”€ uploads/               # Uploaded documents

    â”œâ”€â”€ faiss_index/           # Vector store---

    â””â”€â”€ bm25_index/            # BM25 index

```## âš™ï¸ Configuration



---### Environment Variables



## ğŸ”„ How It Works| Variable | Required | Default | Description |

|----------|----------|---------|-------------|

### 1. Document Processing Pipeline| `GOOGLE_API_KEY` | âœ… Yes | - | Google AI API key for Gemini |

| `DEFAULT_MODEL` | âŒ No | `gemini-2.0-flash` | LLM model to use |

```python

# Load document### Application Settings

doc = process_pdf("document.pdf")

The `config.py` file contains all configurable settings:

# Extract: text, images (as base64), tables (as markdown)

# Chunk: RecursiveCharacterTextSplitter (1000 chars, 200 overlap)```python

# Store: Chunk dataclass with metadataclass Settings:

```    # LLM Settings

    google_api_key: str          # From .env

### 2. Embedding & Indexing    default_model: str           # Gemini model name

    

```python    # Retrieval Settings

# CLIP embeddings (unified space)    top_k_retrieval: int = 10    # Candidates from hybrid search

text_embedding = clip.embed_text(text)      # 512-dim vector    top_k_rerank: int = 3        # Final results after reranking

image_embedding = clip.embed_image(image)   # 512-dim vector (same space!)    

    # Storage Paths

# Store in FAISS    upload_dir: str = "data/uploads"

faiss_index.add(embeddings)  # Cosine similarity via L2 normalization    faiss_index_path: str = "data/faiss_index"

    bm25_index_path: str = "data/bm25_index"

# Store in BM25```

bm25_index.add_document(text)  # Keyword-based ranking

```---



### 3. Retrieval## ğŸš€ Usage



```python### Step 1: Upload Documents

# Reformulate query if follow-up

query = reformulate_query_if_needed(user_input, memory)1. Click the sidebar file uploader

2. Select PDF, PNG, JPG, or TXT files (multiple files supported)

# Hybrid retrieval3. Click **"Process Documents"**

faiss_results = faiss_index.search(query_embedding, top_k=10)4. Wait for indexing to complete (progress shown)

bm25_results = bm25_index.search(query, top_k=10)

### Step 2: Ask Questions

# Fuse with RRF (Reciprocal Rank Fusion)

final_results = rrf_fusion(faiss_results, bm25_results)Type your question in the chat input:



# Rerank with cross-encoder```

reranked = reranker.rank(final_results, top_k=5)"What are the main points in this document?"

```"Summarize the table on page 3"

"What does the diagram show?"

### 4. Generation"Explain the methodology section"

```

```python

# Build context from retrieved chunks### Step 3: View Sources

context = "\n".join([chunk.text for chunk in reranked])

After each response, expand **"ğŸ“š Sources"** to see:

# Generate with Gemini (streaming)- Source file name

response = gemini.generate(context, user_query, memory)- Page number

- Relevant excerpt

# Update memory

memory.add_turn(user_query, response)### Step 4: Conversation Features

```

| Action | How To |

---|--------|--------|

| **Follow-up Questions** | Just ask "Tell me more" or "Explain that further" |

## ğŸ“š API Reference| **Context Awareness** | System remembers last 5 conversation turns |

| **New Chat** | Click "New Chat" to clear conversation history |

### Core Modules| **Clear All** | Click "Clear All" to reset documents and indices |



#### `document_processor.py`---



```python## ğŸ“ Project Structure

from core.document_processor import process_pdf, process_image

```

# Process PDFmultimodal_rag_chatbot/

chunks = process_pdf("document.pdf")â”‚

# Returns: List[Chunk] with text, images (base64), metadataâ”œâ”€â”€ app.py                      # ğŸš€ Streamlit entry point

â”œâ”€â”€ config.py                   # âš™ï¸ Configuration settings

# Process Imageâ”œâ”€â”€ requirements.txt            # ğŸ“¦ Python dependencies

chunks = process_image("image.png")â”œâ”€â”€ .env                        # ğŸ” Environment variables (create this)

# Returns: List[Chunk] with image data and metadataâ”œâ”€â”€ README.md                   # ğŸ“– This documentation

```â”‚

â”œâ”€â”€ core/                       # ğŸ§  Core processing modules

#### `embedding_engine.py`â”‚   â”œâ”€â”€ __init__.py

â”‚   â”œâ”€â”€ document_processor.py   # PDF/image/text extraction, chunking

```pythonâ”‚   â”œâ”€â”€ embedding_engine.py     # CLIP embeddings, FAISS index

from core.embedding_engine import EmbeddingEngineâ”‚   â””â”€â”€ retrieval_engine.py     # BM25, hybrid retrieval, reranking

â”‚

engine = EmbeddingEngine(model_name="sentence-transformers/clip-ViT-B-32")â”œâ”€â”€ services/                   # ğŸ”§ Business logic layer

â”‚   â”œâ”€â”€ __init__.py

# Embed textâ”‚   â”œâ”€â”€ llm_service.py          # Gemini integration, memory, prompts

embedding = engine.embed_text("Hello world")  # 512-dim vectorâ”‚   â””â”€â”€ rag_pipeline.py         # Main RAG orchestration

â”‚

# Embed imageâ”œâ”€â”€ components/                 # ğŸ¨ UI components

embedding = engine.embed_image(image_bytes)   # 512-dim vector (same space)â”‚   â”œâ”€â”€ __init__.py

â”‚   â”œâ”€â”€ sidebar.py              # File upload, controls

# Add chunks to FAISSâ”‚   â”œâ”€â”€ chat_interface.py       # Chat messages display

engine.faiss_index.add_chunks(chunks)â”‚   â””â”€â”€ document_viewer.py      # Source citations display

```â”‚

â”œâ”€â”€ utils/                      # ğŸ› ï¸ Utility functions

#### `retrieval_engine.py`â”‚   â”œâ”€â”€ __init__.py

â”‚   â””â”€â”€ helpers.py              # Helper functions

```pythonâ”‚

from core.retrieval_engine import HybridRetrieverâ””â”€â”€ data/                       # ğŸ’¾ Data storage (auto-created)

    â”œâ”€â”€ uploads/                # Uploaded files

retriever = HybridRetriever(faiss_index, bm25_index, reranker)    â”œâ”€â”€ faiss_index/            # Vector index persistence

    â””â”€â”€ bm25_index/             # Keyword index persistence

# Retrieve relevant chunks```

results = retriever.retrieve(query_embedding, query_text, top_k=5)

# Returns: List[Chunk] ranked by relevance---

```

## ğŸ”„ How It Works

#### `rag_pipeline.py`

### 1. Document Processing Pipeline

```python

from services.rag_pipeline import RAGPipelineWhen you upload a PDF, the system:



pipeline = RAGPipeline()```

PDF Upload

# Process documents    â”‚

pipeline.process_documents(file_paths)    â”œâ”€â”€â†’ TEXT EXTRACTION (PyMuPDF)

    â”‚         â”‚

# Query with streaming    â”‚         â–¼

for chunk in pipeline.query("What is this about?"):    â”‚    Chunking (1000 chars, 200 overlap)

    print(chunk, end="", flush=True)    â”‚    Using RecursiveCharacterTextSplitter

```    â”‚         â”‚

    â”‚         â–¼

#### `llm_service.py`    â”‚    Text Chunks â”€â”€â†’ CLIP Text Encoder â”€â”€â†’ 512-dim Vectors

    â”‚

```python    â”œâ”€â”€â†’ IMAGE EXTRACTION

from services.llm_service import LLMService, ConversationMemory    â”‚         â”‚

    â”‚         â”œâ”€â”€â†’ OCR (EasyOCR) â”€â”€â†’ Text content for display

memory = ConversationMemory(max_turns=5)    â”‚         â”‚

llm = LLMService()    â”‚         â””â”€â”€â†’ Base64 encoding â”€â”€â†’ Stored in Chunk.image_data

    â”‚                   â”‚

# Generate response    â”‚                   â–¼

response = llm.generate_response(    â”‚              CLIP Image Encoder â”€â”€â†’ 512-dim Vectors

    context="...",    â”‚

    query="Question?",    â””â”€â”€â†’ TABLE EXTRACTION (PyMuPDF)

    memory=memory,              â”‚

    stream=True              â–¼

)         Convert to Markdown â”€â”€â†’ CLIP Text Encoder â”€â”€â†’ 512-dim Vectors

```              

              â”‚

---              â–¼

    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”

## ğŸ› Troubleshooting    â”‚  Unified FAISS Index                â”‚

    â”‚  (All vectors in same semantic      â”‚

### Common Issues    â”‚   space - text queries can find     â”‚

    â”‚   relevant images!)                 â”‚

| Problem | Solution |    â”‚                                     â”‚

|---------|----------|    â”‚  + BM25 Keyword Index               â”‚

| **"API key not found"** | Check `.env` file exists and has correct `GOOGLE_API_KEY` |    â”‚  (For lexical matching)             â”‚

| **"Module not found"** | Run `pip install -r requirements.txt` |    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

| **Slow first run** | Models downloading (CLIP, cross-encoder) â€” one-time only |```

| **Out of memory** | Reduce `CHUNK_SIZE` or `MAX_RETRIEVAL_RESULTS` in `config.py` |

| **"FAISS index not found"** | Process documents first using the sidebar button |### 2. Query Processing Pipeline

| **PDF not extracting text** | Check PDF is not scanned image; use OCR (auto-enabled for images) |

| **Embedding dimension mismatch** | Ensure same CLIP model used for all embeddings |When you ask a question:



### Debug Mode```

User Question: "What does the chart on page 5 show?"

Enable debug logging in `config.py`:    â”‚

```python    â–¼

DEBUG = Trueâ”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”

LOGGING_LEVEL = "DEBUG"â”‚  1. QUERY REFORMULATION                                 â”‚

```â”‚     â”œâ”€ Check conversation history                       â”‚

â”‚     â”œâ”€ If follow-up â†’ make standalone using LLM         â”‚

---â”‚     â””â”€ "that chart" â†’ "the chart on page 5"             â”‚

â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

## ğŸ“ License    â”‚

    â–¼

MIT License - see LICENSE file for detailsâ”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”

â”‚  2. HYBRID SEARCH                                       â”‚

---â”‚     â”œâ”€ FAISS Semantic Search (60% weight)               â”‚

â”‚     â”‚   â””â”€ Finds conceptually similar content           â”‚

## ğŸ¤ Contributingâ”‚     â”œâ”€ BM25 Keyword Search (40% weight)                 â”‚

â”‚     â”‚   â””â”€ Finds exact term matches                     â”‚

Contributions welcome! Please:â”‚     â””â”€ RRF (Reciprocal Rank Fusion) combines results    â”‚

â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

1. Fork the repository    â”‚

2. Create a feature branch (`git checkout -b feature/amazing-feature`)    â–¼

3. Commit changes (`git commit -m 'Add amazing feature'`)â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”

4. Push to branch (`git push origin feature/amazing-feature`)â”‚  3. CROSS-ENCODER RERANKING                             â”‚

5. Open a Pull Requestâ”‚     â”œâ”€ Take top 10 candidates                           â”‚

â”‚     â”œâ”€ Score each (query, chunk) pair                   â”‚

---â”‚     â””â”€ Return top 3 most relevant                       â”‚

â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

## ğŸ‘¨â€ğŸ’» Author    â”‚

    â–¼

**Goutam Aswani**â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”

â”‚  4. PROMPT CONSTRUCTION                                 â”‚

---â”‚     â”œâ”€ System prompt with instructions                  â”‚

â”‚     â”œâ”€ Retrieved context with source markers            â”‚

## ğŸ™ Acknowledgmentsâ”‚     â”œâ”€ Conversation history (last 2 turns)              â”‚

â”‚     â””â”€ User question                                    â”‚

- [Google Gemini API](https://ai.google.dev)â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

- [CLIP (OpenAI)](https://github.com/openai/CLIP)    â”‚

- [FAISS (Meta)](https://github.com/facebookresearch/faiss)    â–¼

- [LangChain](https://langchain.com)â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”

- [Streamlit](https://streamlit.io)â”‚  5. LLM GENERATION (Gemini)                             â”‚

â”‚     â”œâ”€ Stream response token by token                   â”‚

---â”‚     â”œâ”€ Include [Source X] citations                     â”‚

â”‚     â””â”€ Save to conversation memory                      â”‚

**Made with â¤ï¸ for multimodal AI**â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

    â”‚
    â–¼
Display in Chat UI with Expandable Sources
```

### 3. Why CLIP for Multimodal Search?

CLIP (Contrastive Language-Image Pre-training) creates a **shared embedding space** for text and images:

```
Text: "solar panel efficiency graph"
                â”‚
                â–¼
        CLIP Text Encoder
                â”‚
                â–¼
        [0.12, -0.45, 0.89, ..., 0.33]  â† 512-dim vector
                â”‚
                â”‚ CLOSE in vector space (high cosine similarity)
                â”‚
                â–¼
        [0.15, -0.42, 0.91, ..., 0.31]  â† 512-dim vector
                â”‚
                â–¼
        CLIP Image Encoder
                â”‚
                â–¼
Image: ğŸ“Š (actual chart of solar panel efficiency)
```

**Benefits:**
- âœ… Text queries can find relevant images
- âœ… Images are searchable by description
- âœ… Unified retrieval across modalities
- âœ… No need for separate image search system

---

## ğŸ“š API Reference

### Core Data Structures

#### `Chunk` (document_processor.py)

The fundamental unit of indexed content:

```python
@dataclass
class Chunk:
    content: str           # Text content or OCR text
    chunk_type: str        # "text" | "table" | "image"
    page_number: int       # Source page number (1-indexed)
    source_file: str       # Source filename
    metadata: dict         # Additional metadata (image dimensions, etc.)
    image_data: str        # Base64-encoded image (for image chunks only)
```

### Core Classes

#### `EmbeddingEngine` (embedding_engine.py)

Handles CLIP embeddings for text and images:

```python
class EmbeddingEngine:
    def __init__(self, model_name: str = "sentence-transformers/clip-ViT-B-32")
    
    def embed_text(self, text: str) -> np.ndarray
        """Embed text using CLIP text encoder. Returns 512-dim vector."""
    
    def embed_image(self, image: PIL.Image) -> np.ndarray
        """Embed image using CLIP image encoder. Returns 512-dim vector."""
    
    def embed_batch(self, texts: List[str]) -> np.ndarray
        """Embed multiple texts efficiently."""
    
    def embed_images_batch(self, images: List[PIL.Image]) -> np.ndarray
        """Embed multiple images efficiently."""
```

#### `FAISSIndex` (embedding_engine.py)

Manages the vector store:

```python
class FAISSIndex:
    def __init__(self, dimension: int = 512)
    
    def add_chunks(self, chunks: List[Chunk]) -> None
        """Add chunks to index. Auto-detects text vs image chunks."""
    
    def search(self, query: str, k: int = 10) -> List[Tuple[Chunk, float]]
        """Search for similar chunks. Returns (chunk, score) pairs."""
    
    def save(self, path: str) -> None
        """Persist index to disk."""
    
    def load(self, path: str) -> bool
        """Load index from disk. Returns True if successful."""
    
    def clear(self) -> None
        """Clear all indexed data."""
```

#### `HybridRetriever` (retrieval_engine.py)

Combines FAISS and BM25 search:

```python
class HybridRetriever:
    def __init__(self, faiss_index: FAISSIndex, bm25_index: BM25Index)
    
    def search(self, query: str, k: int = 10, alpha: float = 0.6) -> List[Chunk]
        """
        Hybrid search using RRF fusion.
        alpha: Weight for vector search (1-alpha for BM25)
        """
```

#### `RAGPipeline` (rag_pipeline.py)

Main orchestration class:

```python
class RAGPipeline:
    def __init__(self)
    
    def process_documents(self, file_paths: List[str]) -> int
        """Process and index documents. Returns number of chunks created."""
    
    def query(self, question: str) -> Generator[str, None, None]
        """Run full RAG pipeline. Yields response tokens."""
    
    def get_sources(self) -> List[Chunk]
        """Get source chunks from last query."""
    
    def get_citations_markdown(self) -> str
        """Get formatted citations markdown."""
    
    def clear_memory(self) -> None
        """Clear conversation memory only."""
    
    def clear(self) -> None
        """Clear all indices and reset state."""
```

#### `ConversationMemory` (llm_service.py)

Manages conversation history:

```python
class ConversationMemory:
    def __init__(self, max_turns: int = 5)
    
    def add_user_message(self, content: str) -> None
    def add_assistant_message(self, content: str) -> None
    def get_history_for_reformulation(self) -> str
    def get_history_for_context(self) -> List[Tuple[str, str]]
    def clear(self) -> None
```

### Key Functions

#### `load_document` (document_processor.py)
```python
def load_document(file_path: str) -> List[Chunk]
    """Load and process a document into chunks. Supports PDF, PNG, JPG, TXT."""
```

#### `reformulate_query` (llm_service.py)
```python
def reformulate_query(query: str, memory: ConversationMemory) -> str
    """Make follow-up questions standalone using conversation history."""
```

#### `generate_response` (llm_service.py)
```python
def generate_response(query: str, chunks: List[Chunk], memory: ConversationMemory) -> Generator[str, None, None]
    """Generate streaming LLM response with RAG context."""
```

---

## ğŸ”§ Troubleshooting

### Common Issues and Solutions

#### 1. Model Download Timeout

**Error:** `ReadTimeoutError: Read timed out`

**Cause:** Slow network when downloading CLIP or Cross-Encoder models

**Solution:**
```bash
# Pre-download models manually
python -c "from sentence_transformers import SentenceTransformer; SentenceTransformer('sentence-transformers/clip-ViT-B-32')"
python -c "from sentence_transformers import CrossEncoder; CrossEncoder('cross-encoder/ms-marco-MiniLM-L-12-v2')"
```

---

#### 2. Corrupted Index Files

**Error:** `EOFError: Ran out of input`

**Cause:** Index files corrupted or from incompatible version

**Solution:**
```powershell
# Delete old indices and reprocess documents
Remove-Item -Recurse -Force data\faiss_index, data\bm25_index
# Then restart app and re-upload documents
```

---

#### 3. Missing API Key

**Error:** `GOOGLE_API_KEY not set` or `Invalid API key`

**Cause:** Missing or incorrect `.env` file

**Solution:**
1. Create `.env` file in project root
2. Add: `GOOGLE_API_KEY=your_actual_key_here`
3. Restart the application

---

#### 4. PNG Color Profile Warning

**Warning:** `libpng warning: iCCP: known incorrect sRGB profile`

**Cause:** PNG images with non-standard color profiles

**Solution:** This is harmless and can be safely ignored. It doesn't affect functionality.

---

#### 5. High Memory Usage

**Cause:** Large documents or many images

**Solutions:**
- Process fewer documents at a time
- Reduce image quality: Change `quality=85` to `quality=60` in `process_pdf()`
- Restart the app to clear memory

---

#### 6. No Results Found

**Cause:** Documents not indexed or query too specific

**Solutions:**
1. Check that "Process Documents" was clicked after upload
2. Try broader search terms
3. Check if documents contain relevant content

---

## ğŸ“Š Performance Considerations

| Factor | Recommendation |
|--------|----------------|
| **Document Size** | Best with PDFs under 50 pages |
| **Image Count** | Performance may degrade with 100+ images |
| **Chunk Size** | Default 1000 chars is optimal for most use cases |
| **Memory** | 4GB+ RAM recommended |
| **First Run** | Model download takes 1-5 minutes |

---

## ğŸ”’ Security Notes

1. **API Keys**: Never commit `.env` to version control
2. **Uploaded Files**: Stored locally in `data/uploads/`
3. **Index Data**: Stored locally in `data/` directory
4. **No External Storage**: All data stays on your machine

---

## ğŸ“ License

This project is licensed under the MIT License.

---

## ğŸ™ Acknowledgments

- [LangChain](https://langchain.com/) - LLM framework
- [Sentence Transformers](https://www.sbert.net/) - CLIP embeddings
- [FAISS](https://github.com/facebookresearch/faiss) - Vector search by Meta
- [Streamlit](https://streamlit.io/) - UI framework
- [Google Gemini](https://ai.google.dev/) - LLM
- [PyMuPDF](https://pymupdf.readthedocs.io/) - PDF processing
- [EasyOCR](https://github.com/JaidedAI/EasyOCR) - OCR engine
